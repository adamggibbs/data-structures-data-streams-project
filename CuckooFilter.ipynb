{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## <u>Cuckoo Filter</u>\n",
    "### Maggie Drew & Adam Gibbs\n",
    "\n",
    "Implementation of Cuckoo Filter for estimating set membership on data streams. Implementation psuedocode from the following paper: https://www.cs.cmu.edu/~dga/papers/cuckoo-conext2014.pdf. This document also helped with figuring out Partial-Kay Cuckoo Hashing: https://williams-cs.github.io/cs358-s20/lectures/lecture10/bloom.pdf. This notebook contains the following:\n",
    "\n",
    "1. Imports used in the notebook\n",
    "2. All global variables and python data structures (lists, dictionaries, etc.) used\n",
    "3. Code for Cuckoo Filter functions\n",
    "4. Cuckoo filter test on simulated data stream\n",
    "5. Results\n",
    "6. Analysis of Results "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import matplotlib as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import gzip\n",
    "import random\n",
    "import math\n",
    "\n",
    "# uncomment if library is needed\n",
    "# !{sys.executable} -m pip install mmh3\n",
    "import mmh3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES and DATA STRUCTURES\n",
    "\n",
    "# dataset to be used as data stream\n",
    "dataset = './input.txt'\n",
    "dataset2 = './input2.txt'\n",
    "\n",
    "# number of buckets in hash table\n",
    "bucket_size = 29\n",
    "# number of fingerprints in each bucket\n",
    "entries_per_bucket = 2\n",
    "\n",
    "# fingerprint size (in bits)\n",
    "fingerprint_size = 7\n",
    "fingerprint_mod = 2**(fingerprint_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class containing basic Cuckoo Filter with insert, lookup, and delete functionality\n",
    "# Creates a Cuckoo Filter with buckets_size buckets\n",
    "# Each bucket has depth 1 and is initialized to NaN to start\n",
    "# Uses mmh3 for hash function, so elements passed into functions should be strings\n",
    "#    however, the element will be cast to a string, so as long as element can be a string you're good\n",
    "\n",
    "class CuckooFilter():\n",
    "\n",
    "\n",
    "    # CONSTRUCTOR\n",
    "    def __init__(self, bucket_size, k=5):\n",
    "        self.bucket_size = bucket_size\n",
    "        self.buckets = np.empty(bucket_size)\n",
    "        self.buckets[:] = np.NaN\n",
    "        self.coefficients = []\n",
    "        for i in range(0,k):\n",
    "            self.coefficients.append(random.uniform(0,7919))\n",
    "    \n",
    "    # HELPER METHODS\n",
    "\n",
    "    # creates fingerprint for element in datastream\n",
    "    def create_fingerprint(self, x):\n",
    "        return mmh3.hash(str(x),5) % fingerprint_mod\n",
    "\n",
    "    # defines our hash function\n",
    "    # for intehers we have modulus bucket_size\n",
    "    def hash1(self, x):\n",
    "        return mmh3.hash(str(x),1) % self.bucket_size\n",
    "\n",
    "    def hash2(self, x):\n",
    "        return mmh3.hash(str(x),2) % self.bucket_size\n",
    "\n",
    "    # def k_ind_hash(self, x):\n",
    "    #     hash_val = self.coefficients[0]\n",
    "    #     for i in range(1, len(self.coefficients)):\n",
    "    #         hash_val += self.coefficients[i]*math.pow(int(x),i)\n",
    "    #     return round(hash_val) % self.bucket_size\n",
    "        \n",
    "\n",
    "    # method used to relocate entries when an incoming element has no free bucket\n",
    "    # returns true if all old buckets are successfully relocated\n",
    "    # returns false if all buckets are filled\n",
    "    def relocate(self, old, bucket):\n",
    "\n",
    "        count = 0\n",
    "        while count < len(self.buckets):\n",
    "            # h1 = self.hash_func(f) % self.bucket_size\n",
    "            # h2 = (h1 ^ self.hash_func(f)) % self.bucket_size\n",
    "            # if h1 == bucket:\n",
    "            #     new_bucket = int(h2)\n",
    "            # else:\n",
    "            #     new_bucket = int(h1)\n",
    "            #print(bucket)\n",
    "            #print(old)\n",
    "            bucket = (bucket ^ self.hash2(int(old))) % self.bucket_size\n",
    "\n",
    "            if pd.isnull(self.buckets[bucket]): \n",
    "                self.buckets[bucket] = old\n",
    "                #print(str(old) + \" in \" + str(bucket))\n",
    "                return True\n",
    "            else:\n",
    "                temp = self.buckets[bucket]\n",
    "                self.buckets[bucket] = old\n",
    "                #print(str(old) + \" in \" + str(bucket))\n",
    "                old = temp\n",
    "            count += 1\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    # CORE METHODS - insert, lookup, and delete\n",
    "\n",
    "    # method used to insert an element\n",
    "    # returns true if the element is inserted\n",
    "    #    or returns true if element has already been inserted\n",
    "    # returns false if the element is not inserted\n",
    "    def insert(self, x):\n",
    "\n",
    "        # get fingerprint for element\n",
    "        f = self.create_fingerprint(x)\n",
    "\n",
    "        # find two hash function values\n",
    "        # second hash function is... \n",
    "        # [hash_func(x) + fingerprint(x)] % bucket_size\n",
    "        h1 = self.hash1(x)\n",
    "        h2 = (h1 ^ self.hash2(f)) % self.bucket_size\n",
    "\n",
    "        # if first bucket is empty or x is already in it,,, add f and return true\n",
    "        # elif second bucket is empty or x is already in it,,, add f and return true\n",
    "        # else randomly pick bucket 1 or 2, then,\n",
    "        # add f to that bucket and relocate the value it replaces, \n",
    "        #    if relocation is successful,,, return true\n",
    "        #    if relocation is not successful,,, undo changes to buckets and return false\n",
    "        if pd.isnull(self.buckets[h1]) or self.buckets[h1] == f:\n",
    "            self.buckets[h1] = f\n",
    "            #print(str(x) + \" in \" + str(h1))\n",
    "            return True\n",
    "        elif pd.isnull(self.buckets[h2]) or self.buckets[h2] == f:\n",
    "            self.buckets[h2] = f\n",
    "            #print(str(x) + \" in \" + str(h2))\n",
    "            return True\n",
    "        else:\n",
    "            rand_num = random.random()\n",
    "            if rand_num < 0.5:\n",
    "                # store buckets in case relocation is unsuccessful\n",
    "                old_buckets = np.copy(self.buckets)\n",
    "                old = self.buckets[h1]\n",
    "                self.buckets[h1] = f\n",
    "                added = self.relocate(old, h1)\n",
    "                \n",
    "                # if relocation is unsuccessful, restore buckets return false\n",
    "                if not added:\n",
    "                    self.buckets = old_buckets\n",
    "                    return added\n",
    "                else:\n",
    "                    return added\n",
    "            else:\n",
    "                # store buckets in case relocation is unsuccessful\n",
    "                old_buckets = np.copy(self.buckets)\n",
    "                old = self.buckets[h2]\n",
    "                self.buckets[h2] = f\n",
    "                added = self.relocate(old, h2)\n",
    "                \n",
    "                # if relocation is unsuccessful, restore buckets return false\n",
    "                if not added:\n",
    "                    self.buckets = old_buckets\n",
    "                    return added\n",
    "                else:\n",
    "                    return added\n",
    "\n",
    "    # method used to determine if an element is in the filter\n",
    "    # gets the fingerprint and calcuates the hash functions, then \n",
    "    # if element is in first or second bucket,,, return true\n",
    "    # otherwise,,, return false\n",
    "    def lookup(self, x):\n",
    "        f = self.create_fingerprint(x)\n",
    "        h1 = self.hash1(x)\n",
    "        h2 = (h1 ^ self.hash2(f)) % self.bucket_size\n",
    "\n",
    "        #print(str(x) + \" h1: \" + str(h1) + \" h2: \" + str(h2))\n",
    "        if self.buckets[h1] == f or self.buckets[h2] == f:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # method used to delete an element in the filter\n",
    "    # gets the fingerprint and calcuates the hash functions, then \n",
    "    # if element is in first bucket, put a NaN in that bucket,,, return true \n",
    "    # if element is in second bucket, put a NaN in that bucket,,, return true \n",
    "    # otherwise element was not in filter,,, return false\n",
    "    def delete(self, x):\n",
    "        f = self.create_fingerprint(x)\n",
    "        h1 = self.hash1(x)\n",
    "        h2 = (h1 ^ self.hash2(f)) % self.bucket_size\n",
    "\n",
    "        if self.buckets[h1] == f:\n",
    "            self.buckets[h1] = np.NaN\n",
    "            return True\n",
    "        elif self.buckets[h2] == f:\n",
    "            self.buckets[h2] = np.NaN\n",
    "            return True\n",
    "        \n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class containing Extended Cuckoo Filter with insert, lookup, and delete functionality\n",
    "# Creates a Cuckoo Filter with buckets_size buckets\n",
    "# Each bucket has depth 1 and is initialized to NaN to start\n",
    "# Uses mmh3 for hash function, so elements passed into functions should be strings\n",
    "#    however, the element will be cast to a string, so as long as element can be a string you're good\n",
    "\n",
    "class ExtendedCuckooFilter():\n",
    "\n",
    "\n",
    "    # CONSTRUCTOR\n",
    "    def __init__(self, bucket_size, entries_per_bucket, k=5):\n",
    "        self.bucket_size = bucket_size\n",
    "        self.entries_per_bucket = entries_per_bucket\n",
    "        #self.buckets = [[np.NaN for num in range(0, entries_per_bucket)] for num in range(0, bucket_size)]\n",
    "        self.buckets = np.empty((bucket_size, entries_per_bucket))\n",
    "        self.buckets[:][:] = np.NaN\n",
    "        self.coefficients = []\n",
    "        for i in range(0,k):\n",
    "            self.coefficients.append(random.uniform(0,7919))\n",
    "    \n",
    "    # HELPER METHODS\n",
    "\n",
    "    # creates fingerprint for element in datastream\n",
    "    def create_fingerprint(self, x):\n",
    "        return mmh3.hash(str(x)) % fingerprint_mod\n",
    "\n",
    "    # defines our hash function\n",
    "    # for intehers we have modulus bucket_size\n",
    "    def hash_func(self, x):\n",
    "        return mmh3.hash(str(x)) % self.bucket_size\n",
    "\n",
    "    def k_ind_hash(self, x):\n",
    "        hash_val = self.coefficients[0]\n",
    "        for i in range(1, len(self.coefficients)):\n",
    "            hash_val += self.coefficients[i]*math.pow(int(x),i)\n",
    "        return round(hash_val) % self.bucket_size\n",
    "        \n",
    "\n",
    "    # method used to relocate entries when an incoming element has no free bucket\n",
    "    # returns true if all old buckets are successfully relocated\n",
    "    # returns false if all buckets are filled\n",
    "    def relocate(self, f, bucket):\n",
    "\n",
    "        count = 0\n",
    "        while count < len(self.buckets):\n",
    "            # h1 = self.hash_func(f)\n",
    "            # h2 = (h1 + hash_func(f)) % self.bucket_size\n",
    "            # if h1 == bucket:\n",
    "            #     new_bucket = int(h2)\n",
    "            # else:\n",
    "            #     new_bucket = int(h1)\n",
    "           \n",
    "            new_bucket = (bucket + self.hash_func(f)) % self.bucket_size\n",
    "\n",
    "            for i in range(0, self.entries_per_bucket):\n",
    "                if pd.isnull(self.buckets[new_bucket][i]): \n",
    "                    self.buckets[new_bucket][i] = f\n",
    "                    return True\n",
    "            \n",
    "            randIndex = random.randint(0,self.entries_per_bucket-1)\n",
    "            old = self.buckets[new_bucket][randIndex]\n",
    "            self.buckets[new_bucket][randIndex] = f\n",
    "            f = old\n",
    "            count += 1\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    # CORE METHODS - insert, lookup, and delete\n",
    "\n",
    "    # method used to insert an element\n",
    "    # returns true if the element is inserted\n",
    "    #    or returns true if element has already been inserted\n",
    "    # returns false if the element is not inserted\n",
    "    def insert(self, x):\n",
    "\n",
    "        # get fingerprint for element\n",
    "        f = self.create_fingerprint(x)\n",
    "\n",
    "        # find two hash function values\n",
    "        # second hash function is... \n",
    "        # [hash_func(x) + fingerprint(x)] % bucket_size\n",
    "        h1 = self.hash_func(x)\n",
    "        h2 = (h1 + self.hash_func(f)) % self.bucket_size\n",
    "\n",
    "        # if first bucket is empty or x is already in it,,, add f and return true\n",
    "        # elif second bucket is empty or x is already in it,,, add f and return true\n",
    "        # else randomly pick bucket 1 or 2, then,\n",
    "        # add f to that bucket and relocate the value it replaces, \n",
    "        #    if relocation is successful,,, return true\n",
    "        #    if relocation is not successful,,, undo changes to buckets and return false\n",
    "\n",
    "        for i in range(0, self.entries_per_bucket):\n",
    "            if pd.isnull(self.buckets[h1][i]) or self.buckets[h1][i] == f:\n",
    "                self.buckets[h1][i] = f\n",
    "                return True\n",
    "        for i in range(0, self.entries_per_bucket):\n",
    "            if pd.isnull(self.buckets[h2][i]) or self.buckets[h2][i] == f:\n",
    "                self.buckets[h2][i] = f\n",
    "                return True\n",
    "        \n",
    "        rand_num = random.random()\n",
    "        if rand_num < 0.5:\n",
    "            # store buckets in case relocation is unsuccessful\n",
    "            old_buckets = np.copy(self.buckets)\n",
    "            randIndex = random.randint(0,self.entries_per_bucket-1)\n",
    "            old = self.buckets[h1][randIndex]\n",
    "            self.buckets[h1][randIndex] = f\n",
    "            added = self.relocate(old, h1)\n",
    "            \n",
    "            # if relocation is unsuccessful, restore buckets return false\n",
    "            if not added:\n",
    "                self.buckets = old_buckets\n",
    "                return added\n",
    "            else:\n",
    "                return added\n",
    "        else:\n",
    "            # store buckets in case relocation is unsuccessful\n",
    "            old_buckets = np.copy(self.buckets)\n",
    "            randIndex = random.randint(0,self.entries_per_bucket-1)\n",
    "            old = self.buckets[h2][randIndex]\n",
    "            self.buckets[h2][randIndex] = f\n",
    "            added = self.relocate(old, h2)\n",
    "            \n",
    "            # if relocation is unsuccessful, restore buckets return false\n",
    "            if not added:\n",
    "                self.buckets = old_buckets\n",
    "                return added\n",
    "            else:\n",
    "                return added\n",
    "\n",
    "    # method used to determine if an element is in the filter\n",
    "    # gets the fingerprint and calcuates the hash functions, then \n",
    "    # if element is in first or second bucket,,, return true\n",
    "    # otherwise,,, return false\n",
    "    def lookup(self, x):\n",
    "        f = self.create_fingerprint(x)\n",
    "        h1 = self.hash_func(x)\n",
    "        h2 = (h1 + self.hash_func(f)) % self.bucket_size\n",
    "\n",
    "        for i in range(0, self.entries_per_bucket):\n",
    "\n",
    "            if self.buckets[h1][i] == f or self.buckets[h2][i] == f:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # method used to delete an element in the filter\n",
    "    # gets the fingerprint and calcuates the hash functions, then \n",
    "    # if element is in first bucket, put a NaN in that bucket,,, return true \n",
    "    # if element is in second bucket, put a NaN in that bucket,,, return true \n",
    "    # otherwise element was not in filter,,, return false\n",
    "    def delete(self, x):\n",
    "        f = self.create_fingerprint(x)\n",
    "        h1 = self.hash_func(x)\n",
    "        h2 = (h1 + self.hash_func(f)) % self.bucket_size\n",
    "\n",
    "        for i in range(0, self.entries_per_bucket):\n",
    "            if self.buckets[h1][i] == f:\n",
    "                self.buckets[h1][i] = np.NaN\n",
    "                return True\n",
    "\n",
    "        for i in range(0, self.entries_per_bucket):\n",
    "            if self.buckets[h2][i] == f:\n",
    "                self.buckets[h2][i] = np.NaN\n",
    "                return True\n",
    "        \n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Insert 5? True f= 103\nInsert 4? True f= 91\nInsert 9? True f= 17\nInsert 11? True f= 12\nInsert 33? True f= 23\nInsert 46? True f= 30\nInsert 77? True f= 31\nInsert 4? True f= 91\nInsert 9? True f= 17\nInsert 13? True f= 76\nInsert 42? True f= 22\nInsert 155? True f= 104\nInsert 207? True f= 37\n\nFilter: \n[ 12.  nan  nan  nan  22.  nan  nan  76.  nan  nan  nan  23.  91.  nan\n 103.  nan  nan  nan  37.  nan  nan  31.  nan  nan 104.  nan  nan  30.\n  17.]\n"
     ]
    }
   ],
   "source": [
    "# READ IN DATA AND APPLY FILTER\n",
    "\n",
    "cf = CuckooFilter(bucket_size)\n",
    "\n",
    "with open(dataset, 'rt') as data_stream:\n",
    "    for line in data_stream:\n",
    "        for element in line.split():\n",
    "            print(\"Insert \" + str(element) + \"? \" + str(cf.insert(element)) + \" f=\" + \" \" + str(cf.create_fingerprint(element)))\n",
    "print(\"\\nFilter: \\n\" + str(cf.buckets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9\n140\n3\n5\n3\n5\n5\n"
     ]
    }
   ],
   "source": [
    "ele = \"11\"\n",
    "\n",
    "size = bucket_size\n",
    "print(size)\n",
    "\n",
    "def hash1(x):\n",
    "    return mmh3.hash(str(x),1) % size\n",
    "def hash2(x):\n",
    "    return mmh3.hash(str(x),2) % size\n",
    "\n",
    "def fing(x):\n",
    "    return mmh3.hash(str(x),5) % fingerprint_mod\n",
    "\n",
    "fp = fing(ele)\n",
    "print(fp)\n",
    "\n",
    "b1 = hash1(ele)\n",
    "b2 = (b1 ^ hash2(fp)) % size\n",
    "\n",
    "print(b1)\n",
    "print(b2)\n",
    "\n",
    "bucket = b2\n",
    "\n",
    "bucket = (bucket ^ hash2(fp)) % size\n",
    "print(bucket)\n",
    "print((bucket ^ hash2(fp)) % size)\n",
    "\n",
    "print((3 ^ hash2(140)) % size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lookup 5? True\nLookup 4? True\nLookup 9? True\nLookup 11? True\nLookup 33? True\nLookup 46? True\nLookup 77? True\nLookup 4? True\nLookup 9? True\nLookup 13? True\nLookup 42? True\nLookup 155? True\nLookup 207? True\n\nLookup 36? False\nLookup 75? False\nLookup 3? False\nLookup 0? False\nLookup 101? False\n"
     ]
    }
   ],
   "source": [
    "# lookup every element that is added to the filter\n",
    "# return true is expected as Cuckoo Filters have no false negatives\n",
    "with open(dataset, 'rt') as data_stream:\n",
    "    for line in data_stream:\n",
    "        for element in line.split():\n",
    "            print(\"Lookup \" + str(element) + \"? \" + str(cf.lookup(element)))\n",
    "\n",
    "print()\n",
    "\n",
    "# lookup 5 values that were not inserted into the filter\n",
    "# return false expected, but there could be false positives\n",
    "# however, false positives will such a low number of insertions are rare\n",
    "for test in ['36', '75', '3', '0', '101']:\n",
    "    print(\"Lookup \" + str(test) + \"? \" + str(cf.lookup(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n2\n"
     ]
    }
   ],
   "source": [
    "print(cf.hash1(\"4\"))\n",
    "print((cf.hash1(\"4\") ^ cf.create_fingerprint(\"4\"))%bucket_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\nTrue\nFalse\n\nFalse\nFalse\nFalse\nFalse\n"
     ]
    }
   ],
   "source": [
    "# delete 3 elements that are in the filter\n",
    "# return true expected\n",
    "print(cf.delete('5'))\n",
    "print(cf.delete('33'))\n",
    "print(cf.delete('77'))\n",
    "# delete an element that is not in the filter\n",
    "# return false expected\n",
    "print(cf.delete('55'))\n",
    "\n",
    "print()\n",
    "\n",
    "# see if any deleted elements remain in the filter\n",
    "# return false expected every time\n",
    "print(cf.lookup('5'))\n",
    "print(cf.lookup('33'))\n",
    "print(cf.lookup('77'))\n",
    "print(cf.lookup('55'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Insert aarp? True\nInsert abandon? True\nInsert abandoned? True\nInsert abandoning? True\nInsert abb? True\nInsert abc? True\nInsert abcs? True\nInsert aboard? True\nInsert abortion? True\n\nFilter: \n[ 8. nan nan nan nan 29. 47. nan nan 19. nan nan nan 49. nan nan nan nan\n nan nan nan nan 26. 25. nan 60. nan nan 98.]\n"
     ]
    }
   ],
   "source": [
    "# READ IN DATA AND APPLY FILTER\n",
    "\n",
    "cf2 = CuckooFilter(bucket_size)\n",
    "\n",
    "with open(dataset2, 'rt') as data_stream:\n",
    "    for line in data_stream:\n",
    "        for element in line.split():\n",
    "            print(\"Insert \" + str(element) + \"? \" + str(cf2.insert(element)))\n",
    "print(\"\\nFilter: \\n\" + str(cf2.buckets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lookup aarp? True\nLookup abandon? True\nLookup abandoned? True\nLookup abandoning? True\nLookup abb? True\nLookup abc? True\nLookup abcs? True\nLookup aboard? True\nLookup abortion? True\n\nLookup mirror? False\nLookup hello? False\nLookup bird? False\nLookup super? False\nLookup raspberry? False\n"
     ]
    }
   ],
   "source": [
    "# lookup every element that is added to the filter\n",
    "# return true is expected as Cuckoo Filters have no false negatives\n",
    "with open(dataset2, 'rt') as data_stream:\n",
    "    for line in data_stream:\n",
    "        for element in line.split():\n",
    "            print(\"Lookup \" + str(element) + \"? \" + str(cf2.lookup(element)))\n",
    "\n",
    "print()\n",
    "\n",
    "# lookup 5 values that were not inserted into the filter\n",
    "# return false expected, but there could be false positives\n",
    "# however, false positives will such a low number of insertions are rare\n",
    "for test in ['mirror', 'hello', 'bird', 'super', 'raspberry']:\n",
    "    print(\"Lookup \" + str(test) + \"? \" + str(cf2.lookup(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\nFalse\n\nFalse\nFalse\nFalse\n"
     ]
    }
   ],
   "source": [
    "# delete 3 elements that are in the filter\n",
    "# return true expected\n",
    "print(cf2.delete('aarp'))\n",
    "print(cf2.delete('abortion'))\n",
    "# delete an element that is not in the filter\n",
    "# return false expected\n",
    "print(cf2.delete('mirror'))\n",
    "\n",
    "print()\n",
    "\n",
    "# see if any deleted elements remain in the filter\n",
    "# return false expected every time\n",
    "print(cf2.lookup('aarp'))\n",
    "print(cf2.lookup('abortion'))\n",
    "print(cf2.lookup('mirror'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}